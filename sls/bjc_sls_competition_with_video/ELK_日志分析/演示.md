

es -head 的 地址 http://10.100.254.149:9100/

es-head 的启动： cd /root/elasticsearch/plugins/elasticsearch-head-master;  npm run start &

# 基础架构痛点

	1.	使用logstash 采集，Logstash 占用内存高，部署到生产机器上占用资源高。

	2.	日志无格式化解析，logstash 的grok 插件在面对一定数量级的日志时效率非常低。并且cpu 占用率非常高。

	3.	大的数据量写入，总的存储比较多---不能所有节点都写入，不能所有数据都存在线上。  三天内查询频率高，3天外的查询频率比较低。 如果都一视同仁，冷节点cpu 利用率比较低

# 解决方案

  1.  引入更轻量级filebeat 代替 logstash 进行采集，降低内存使用率提高采集效率。
  2.  引入kafuka 作为数据中间件，作为消息队列解耦了处理过程，同时提高了可扩展性。具有峰值处理能力，使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。
  3.  引入flink 相对logstash 的grok 模式，有更快的计算能力和更低的数据延迟，并且支持双流join。在实时处理流数据方面性能更好。
  4.  冷热节点，读写分离。     热节点（物理机器）主要承担实时日志写入以及最近3天日志的日志搜索查询，对于查询频次较低的3天以前的日志则全部迁移到冷节点（docker）. 利用 定时任务来实现 冷热分离，读写分离


### 如何实现数据从hot节点迁移到老的cold节点?
[文章参考](https://blog.csdn.net/xiaomin1991222/article/details/84761265?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_baidulandingword-6&spm=1001.2101.3001.4242)

以test—bjc-2020.12.27索引为例,将它从hot节点迁移到cold节点

kibana里操作:
```
PUT /test—bjc-2020.12.27/_settings 
{ 
  "settings": { 
    "index.routing.allocation.require.box_type": "cold"
  } 
}
```
## 如何实现读写分离
1  将 duplicate 分配 到指定节点
POST /_cluster/reroute
{
    "commands" : [ {
        {
          "allocate" : {
              "index" : "test_index_01", "shard" : 1, "node-4" : "node3"
          }
        }
    ]
}

2 读写数据都分布到了不同的集群上，下面看看如何在指定查询参数，只查询stale集群节点上的数据。
POST /_search?preference=_only_nodes:zone:stale
{
    "query": {
        "match": {
            "title": "elasticsearch"
        }
    }
}

